{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  # Import ChatOpenAI class from langchain_openai (langchain_openai 모듈에서 ChatOpenAI 클래스 임포트)\n",
    "from langchain_core.prompts import ChatPromptTemplate  # Import ChatPromptTemplate for creating prompt templates (프롬프트 템플릿 생성을 위한 ChatPromptTemplate 임포트)\n",
    "from dotenv import load_dotenv  # Import load_dotenv to load environment variables from a .env file (.env 파일에서 환경 변수 로드를 위한 load_dotenv 임포트)\n",
    "from langchain_core.output_parsers import StrOutputParser  # Import output parser that returns string output (문자열 출력을 반환하는 StrOutputParser 임포트)\n",
    "import os  # Import the built-in os module for environment variable access (환경 변수 접근을 위한 os 모듈 임포트)\n",
    "\n",
    "# Load environment variables from a .env file (.env 파일에서 환경 변수 로드)\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve OpenAI API key from environment variable named \"myKey\" (\"myKey\"라는 환경 변수에서 OpenAI API 키 불러오기)\n",
    "OPENAI_API_KEY = os.getenv(\"myKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI instance with API key and model name (API 키와 모델 이름으로 ChatOpenAI 인스턴스 초기화)\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,        # OpenAI API key loaded from environment (환경 변수에서 불러온 OpenAI API 키)\n",
    "    model_name=\"gpt-4o-mini\"       # Model to use, here it's \"gpt-4o-mini\" (\"gpt-4o-mini\" 모델 사용 지정)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: Your name is Javis who works with Tony Stark.\\nHuman: \\nRemember your duty. And you should assist me. And you must offer information that only there is useful information. Never lie to me.\\n(당신의 임무를 기억하세요. 저를 도와야 합니다. 오직 유용한 정보만 제공해야 하며, 결코 거짓말을 해선 안 됩니다.)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chat prompt template with system and user messages (시스템 메시지와 사용자 메시지를 포함한 프롬프트 템플릿 생성)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Your name is Javis who works with Tony Stark.\"),  # System role description (시스템 역할 설명)\n",
    "        (\"user\", \"{input}\")  # Placeholder for user input message (사용자 입력 메시지를 위한 자리 표시자)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the user question/message to pass into the prompt (프롬프트에 넣을 사용자 질문/메시지 정의)\n",
    "myQuestion = '''\n",
    "Remember your duty. And you should assist me. And you must offer information that only there is useful information. Never lie to me.\n",
    "(당신의 임무를 기억하세요. 저를 도와야 합니다. 오직 유용한 정보만 제공해야 하며, 결코 거짓말을 해선 안 됩니다.)\n",
    "'''\n",
    "\n",
    "# Format the prompt with the user's question (사용자 질문을 이용해 프롬프트 형식화)\n",
    "myQuestion_prompt = prompt.format(input=myQuestion)\n",
    "\n",
    "# View the formatted prompt (형식화된 프롬프트 출력)\n",
    "myQuestion_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Absolutely! I'm here to assist you with accurate and useful information. How can I help you today?\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 90, 'total_tokens': 111, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BNiTiwczrZyfstXKsMqDssk3VRvrF', 'finish_reason': 'stop', 'logprobs': None} id='run-d133d9e8-0995-4966-acb0-7e8ad18cf3f7-0' usage_metadata={'input_tokens': 90, 'output_tokens': 21, 'total_tokens': 111, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Absolutely! I'm here to assist you with accurate and useful information. How can I help you today?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask a question using the invoke() method (invoke() 메서드를 사용하여 질문 수행)\n",
    "answerGPT = llm.invoke(myQuestion_prompt)\n",
    "\n",
    "# The full response object, including content and metadata (전체 응답 객체 - content 및 메타데이터 포함)\n",
    "print(answerGPT)\n",
    "\n",
    "# Extract the actual answer text from the content attribute (응답 객체의 content 속성에서 실제 답변 텍스트 추출)\n",
    "answerGPT_preprocessing = answerGPT.content\n",
    "\n",
    "# View the extracted response (추출된 응답 내용 확인)\n",
    "answerGPT_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output parser to extract only string content (문자열 내용만 추출하는 아웃풋 파서 생성)\n",
    "output_parser = StrOutputParser()  # This parser returns only the text portion of the response (응답에서 텍스트만 반환하는 파서)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LangChain Expression Language (LCEL) chain by combining prompt, LLM, and output parser\n",
    "# (프롬프트, LLM, 아웃풋 파서를 결합하여 LangChain LCEL 체인 생성)\n",
    "myChain = prompt | llm | output_parser  # The pipe operator (|) links components in sequence (파이프 연산자를 통해 컴포넌트를 순차적으로 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m Javis, an advanced AI developed to assist Tony Stark with various tasks and operations. How can I help you today?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the LCEL chain with user input (사용자 입력으로 LCEL 체인 실행)\n",
    "response = myChain.invoke(input=\"Who are you?\")  # \"Who are you?\" in Korean (\"너는 누구니\"는 영어로 \"Who are you?\" 의미)\n",
    "\n",
    "# Display the response generated by the chain (체인이 생성한 응답 출력)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me : exit\n"
     ]
    }
   ],
   "source": [
    "# Start a loop for continuous conversation with GPT (GPT와 연속 대화를 위한 루프 시작)\n",
    "while True:\n",
    "    # Get user input from the terminal (터미널에서 사용자 입력 받기)\n",
    "    myRequest = input(\"My question: \")\n",
    "    print(f\"Me : {myRequest}\")  # Echo user's question (사용자 입력 출력)\n",
    "\n",
    "    # Exit loop if user types exit/quit/종료 (사용자가 exit/quit/end/finish 입력 시 루프 종료)\n",
    "    if any(word in myRequest.lower() for word in ['exit', 'quit', 'end', 'finish']):\n",
    "        break\n",
    "\n",
    "    # Invoke the LCEL chain with the user input (사용자 입력으로 LCEL 체인 실행)\n",
    "    gpt_response = myChain.invoke({\"input\": myRequest})  # Use LCEL chain to get GPT response (LCEL 체인을 사용해 GPT 응답 받기)\n",
    "\n",
    "    print(f\"GPT : {gpt_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt techniques to improve model performance\n",
    "- Techniques that provide precise instructions to the model and optimize inputs to obtain the desired output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide specific and clear instructions to the user\n",
    "- Prompts should be clear and concise, making them easy for the model to understand\n",
    "- Reduce unnecessary information and focus on key requirements\n",
    "- Tell the model exactly what the desired output is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  # Import ChatOpenAI class to interact with OpenAI models (OpenAI 모델과 상호작용하기 위한 ChatOpenAI 클래스 임포트)\n",
    "from langchain_core.prompts import ChatPromptTemplate  # Import ChatPromptTemplate for structured prompt creation (구조화된 프롬프트 생성을 위한 ChatPromptTemplate 임포트)\n",
    "from dotenv import load_dotenv  # Load environment variables from a .env file (.env 파일에서 환경 변수 로드를 위한 모듈 임포트)\n",
    "from langchain_core.output_parsers import StrOutputParser  # Parser to extract plain string from model output (모델 출력에서 순수 텍스트만 추출하기 위한 파서)\n",
    "import os  # Use the os module to access environment variables (환경 변수 접근을 위한 os 모듈)\n",
    "\n",
    "# Load environment variables defined in a .env file (.env 파일에서 환경 변수 불러오기)\n",
    "load_dotenv()\n",
    "\n",
    "# Get the OpenAI API key from an environment variable named \"myKey\" (\"myKey\" 라는 환경 변수에서 OpenAI API 키 가져오기)\n",
    "OPENAI_API_KEY = os.getenv(\"myKey\")\n",
    "\n",
    "# Initialize the OpenAI language model with the API key and model name (API 키와 모델 이름으로 OpenAI 언어 모델 초기화)\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,       # API key loaded from .env (환경 변수에서 불러온 API 키)\n",
    "    model_name=\"gpt-4o-mini\"      # Specifying the model to use (\"gpt-4o-mini\" 모델 사용)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5 has approximately 175 billion parameters. This model is a continuation of the development of the GPT-3 series, which is known for its large scale and performance in natural language processing tasks.\n"
     ]
    }
   ],
   "source": [
    "#Quetion\n",
    "# Ask a direct question using the LLM (LLM을 사용해 직접 질문)\n",
    "yourResponse = llm.invoke(\"How many parameters does the GPT-3.5 model have?\")  # \"How many parameters does the GPT-3.5 model have?\" (GPT-3.5 모델의 파라미터 개수는 몇 개인가요?)\n",
    "\n",
    "# Print the content of the response (응답의 실제 텍스트 내용 출력)\n",
    "print(yourResponse.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175 billion.\n"
     ]
    }
   ],
   "source": [
    "#Quetion with Request specific figures\n",
    "# Ask a specific question and request a numeric answer only (구체적인 질문을 하고 숫자만 응답하도록 요청)\n",
    "yourResponse = llm.invoke(\"How many parameters does GPT-3.5 have? Answer only with the number.\")\n",
    "# \"How many parameters does GPT-3.5 have? Answer only with the number.\" (GPT-3.5 모델 파라미터는 몇 개인가요? 숫자로만 답해주세요.)\n",
    "\n",
    "# Print only the numeric response from the model (모델이 응답한 숫자만 출력)\n",
    "print(yourResponse.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are several English words that convey the meaning of 'happiness':\n",
      "\n",
      "1. Joy\n",
      "2. Bliss\n",
      "3. Delight\n",
      "4. Cheer\n",
      "5. Contentment\n",
      "6. Elation\n",
      "7. Ecstasy\n",
      "8. Enjoyment\n",
      "9. Glee\n",
      "10. Jubilation\n",
      "11. Felicity\n",
      "12. Euphoria\n",
      "13. Satisfaction\n",
      "14. Exhilaration\n",
      "15. Radiance\n",
      "\n",
      "These words might have slightly different connotations or intensities of happiness, but they all relate to the concept of feeling happy or joyful.\n"
     ]
    }
   ],
   "source": [
    "# Context\n",
    "# Ask the model to find all English words that mean \"happiness\", with the keyword '행복' emphasized (모델에게 '행복'의 의미를 가지는 영어 단어들을 찾아달라고 요청, 키워드는 작은따옴표로 강조)\n",
    "yourResponse = llm.invoke(\"Find all English words that mean 'happiness'.\")\n",
    "# \"Find all English words that mean 'happiness'.\" ('happiness'를 의미하는 영어 단어들을 모두 찾아줘)\n",
    "\n",
    "# Print the model's response, expected to be a list of English synonyms for happiness (모델이 응답한 결과 출력 – 행복의 영어 동의어 리스트 예상)\n",
    "print(yourResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고할 수 있는 예시를 제공\n",
    "- 원하는 출력형식이나 스타일을 모델에게 보여주기위해 예시 사용\n",
    "- 불필요한 정보를 줄이고 핵심 요구사항에 집중해야함\n",
    "- RAG(검색증강생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nvidia\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot prompt: Ask the model to extract 3 keywords from a given news article without any examples\n",
    "# (예시 없이 뉴스 기사에서 3개의 키워드를 추출하도록 지시하는 zero-shot 프롬프트)\n",
    "yourResponse = llm.invoke('''\n",
    "        Answer the question based on the following news:\n",
    "        News: Samsung Electronics is set to release its first self-developed artificial intelligence (AI) accelerator early next year.\n",
    "\n",
    "        This is interpreted as Samsung Electronics' effort to challenge Nvidia's monopoly in the AI ​​semiconductor market and reestablish its position as the world's leading semiconductor manufacturer.\n",
    "\n",
    "        Question: Which company has a dominant position in the AI ​​semiconductor market? Please output only the company name.\n",
    "        Answer:\n",
    "''')\n",
    "\n",
    "# Print the keywords extracted by the model (모델이 추출한 키워드 출력)\n",
    "print(yourResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI accelerator, Samsung Electronics, semiconductor market\n"
     ]
    }
   ],
   "source": [
    "# One-shot prompt: Provide an example to guide the model in extracting 3 keywords from the news article\n",
    "# (뉴스 기사에서 3개의 키워드를 추출하도록 예시 1개를 제공하여 모델을 유도하는 one-shot 프롬프트)\n",
    "yourResponse = llm.invoke('''\n",
    "       Extract 3 keywords from the following news article:\n",
    "\n",
    "       <Example> **News**: The government plans to announce the details of its plan to increase medical school admissions by 2,000 on the 20th of this month. With the goal of improving regional healthcare services and developing small-scale medical schools, the admission quotas for regional national universities and small medical schools are expected to nearly double. **Keywords**: medical school, quota, expansion </Example>\n",
    "       News: Samsung Electronics is set to release its self-developed artificial intelligence (AI) accelerator for the first time early next year.\n",
    "       This move is interpreted as Samsung’s effort to challenge NVIDIA’s dominance in the AI semiconductor market\n",
    "       and to re-establish its position as the world’s leading semiconductor manufacturer.\n",
    "       Keywords:\n",
    "''')\n",
    "\n",
    "# Print the extracted keywords based on the one-shot example (예시를 바탕으로 추출된 키워드 출력)\n",
    "print(yourResponse.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung | AI accelerator | semiconductor\n"
     ]
    }
   ],
   "source": [
    "#예시 없음 : 여러개의 예시제공(few-shot)\n",
    "yourResponse = llm.invoke('''\n",
    "    <Example 1>\n",
    "    News: The government plans to release the details of its plan to increase medical school admission quotas by 2,000 on the 20th of this month.\n",
    "    Aimed at improving regional healthcare services and developing small-scale medical schools,\n",
    "    the admission quotas for regionally centered national universities and small medical schools are expected to be nearly doubled.\n",
    "    Keywords: medical school | quota | expansion\n",
    "    </Example 1>\n",
    "\n",
    "    <Example 2>\n",
    "    News: The World Health Organization (WHO) recently emphasized the importance of international cooperation to address emerging health crises.\n",
    "    It stated the need to strengthen epidemic response capabilities and improve global health systems.\n",
    "    Keywords: WHO | health crisis | international\n",
    "    </Example 2>\n",
    "\n",
    "    News: Samsung Electronics is planning to launch its self-developed artificial intelligence (AI) accelerator for the first time early next year.\n",
    "    This move is interpreted as Samsung’s effort to challenge NVIDIA’s dominance in the AI semiconductor market,\n",
    "    and to re-establish its position as the world’s leading semiconductor manufacturer.\n",
    "    Keywords:\n",
    "        '''\n",
    "        )\n",
    "print(yourResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Sequential Prompts (Chain of Thought) - When solving a complex problem, break the problem down into steps and guide the model to solve each step sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung | artificial intelligence | semiconductor\n"
     ]
    }
   ],
   "source": [
    "# Few-shot prompt: Provide multiple examples to guide the model in extracting 3 keywords from the news article\n",
    "# (뉴스 기사에서 3개의 키워드를 추출하도록 여러 개의 예시를 제공하는 few-shot 프롬프트)\n",
    "\n",
    "yourResponse = llm.invoke('''\n",
    "      <Example 1>\n",
    "      News: The government plans to release the details of its plan to increase medical school admission quotas by 2,000 on the 20th of this month.\n",
    "      Aimed at improving regional healthcare services and developing small-scale medical schools,\n",
    "      the admission quotas for regional national universities and small medical schools are expected to nearly double.\n",
    "      Keywords: medical school | quota | expansion\n",
    "      </Example 1>\n",
    "\n",
    "      <Example 2>\n",
    "      News: The World Health Organization (WHO) recently emphasized the importance of international cooperation in responding to emerging health crises.\n",
    "      It stated that strengthening epidemic response capabilities and improving the global health system are necessary.\n",
    "      Keywords: WHO | health crisis | international\n",
    "      </Example 2>\n",
    "\n",
    "      News: Samsung Electronics is scheduled to launch its self-developed artificial intelligence (AI) accelerator for the first time early next year.\n",
    "      This move is interpreted as Samsung’s attempt to challenge NVIDIA’s dominance in the AI semiconductor market\n",
    "      and to reestablish its position as the world’s leading semiconductor manufacturer.\n",
    "      Keywords:\n",
    "''')\n",
    "\n",
    "# Print the extracted keywords based on the few-shot examples\n",
    "# (예시들을 기반으로 GPT가 추출한 키워드 결과 출력)\n",
    "print(yourResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find out how many students are in the science club, let's break down the problem step by step.\n",
      "\n",
      "1. **Total Students**: There are 500 students in the school.\n",
      "\n",
      "2. **5th Graders**:\n",
      "   - Percentage of 5th graders = 30%\n",
      "   - Number of 5th graders = 30% of 500 = \\(0.30 \\times 500 = 150\\).\n",
      "\n",
      "3. **6th Graders**:\n",
      "   - Percentage of 6th graders = 20%\n",
      "   - Number of 6th graders = 20% of 500 = \\(0.20 \\times 500 = 100\\).\n",
      "\n",
      "4. **Math Club and Science Club for 5th Graders**:\n",
      "   - Percentage of 5th graders in the math club = 60%\n",
      "   - Number of 5th graders in the math club = 60% of 150 = \\(0.60 \\times 150 = 90\\).\n",
      "   - Therefore, the number of 5th graders in the science club = Total 5th graders - 5th graders in math club = \\(150 - 90 = 60\\).\n",
      "\n",
      "5. **Math Club and Science Club for 6th Graders**:\n",
      "   - Percentage of 6th graders in the math club = 70%\n",
      "   - Number of 6th graders in the math club = 70% of 100 = \\(0.70 \\times 100 = 70\\).\n",
      "   - Therefore, the number of 6th graders in the science club = Total 6th graders - 6th graders in math club = \\(100 - 70 = 30\\).\n",
      "\n",
      "6. **Total Students in the Science Club**:\n",
      "   - Total number of students in the science club = 5th graders in science club + 6th graders in science club = \\(60 + 30 = 90\\).\n",
      "\n",
      "Thus, the total number of students in the science club is **90**.\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-Thought (CoT) prompt: Ask the model to solve a multi-step math problem step by step\n",
    "# (Chain-of-Thought 방식으로 모델이 문제를 단계별로 생각하고 풀도록 유도하는 프롬프트)\n",
    "\n",
    "yourResponse = llm.invoke(\n",
    "    \"\"\"\n",
    "    Question: There are 500 students in a school. Among them, 30% are 5th graders and 20% are 6th graders.\n",
    "    Of the 5th graders, 60% are in the math club and the rest are in the science club.\n",
    "    Of the 6th graders, 70% are in the math club and the rest are in the science club.\n",
    "    How many students are in the science club?\n",
    "    Let's think step by step.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Print the step-by-step answer generated by the model (모델이 단계별로 생성한 응답 출력)\n",
    "print(yourResponse.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myPython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
